{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"http://www.gutenberg.org/files/2554/2554.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "# print(type(raw))\n",
    "# print(len(raw))\n",
    "# print(raw[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Tokenize'''\n",
    "tokens = word_tokenize(raw)\n",
    "# print(type(tokens))\n",
    "# print(len(tokens))\n",
    "# print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nltk.pos_tag(tokens[1026:1062])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english') #delete stopwords from data\n",
    "clean_tokens = [w for w in tokens if w.lower() not in stopwords]\n",
    "# print(clean_tokens[586:607])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_sent = clean_tokens[586:607]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#lemmatizer.lemmatize(first_sent[7]) #'came'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lemmatizer.lemmatize(first_sent[7], pos=\"v\") #'came'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('/Users/hclent/Desktop/NLPtutorial/texts/document.txt', 'r')\n",
    "for line in f:\n",
    "    sentence = line.strip()\n",
    "    #print(sentence)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pyNLP]",
   "language": "python",
   "name": "conda-env-pyNLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
