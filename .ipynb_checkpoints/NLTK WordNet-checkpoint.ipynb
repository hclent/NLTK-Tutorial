{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from more_itertools import unique_everseen\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('car.n.01'), Synset('car.n.02'), Synset('car.n.03'), Synset('car.n.04'), Synset('cable_car.n.01')]\n"
     ]
    }
   ],
   "source": [
    "'''WordNet is a semantically-oriented dictionary of English, similar to a traditional thesaurus but \n",
    "with a richer structure. NLTK includes the English WordNet, with 155,287 words and 117,659 synonym sets. \n",
    "We'll begin by looking at synonyms and how they are accessed in WordNet.'''\n",
    "\n",
    "print(wn.synsets('car'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'auto', 'automobile', 'machine', 'motorcar']\n",
      "['car', 'railcar', 'railway_car', 'railroad_car']\n",
      "['car', 'gondola']\n",
      "['car', 'elevator_car']\n",
      "['cable_car', 'car']\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('car'):\n",
    "    print(synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he needs a car to get to work']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Model_T', 'S.U.V.', 'SUV', 'Stanley_Steamer', 'ambulance', 'beach_waggon', 'beach_wagon', 'bus', 'cab', 'compact', 'compact_car', 'convertible', 'coupe', 'cruiser', 'electric', 'electric_automobile', 'electric_car', 'estate_car', 'gas_guzzler', 'hack', 'hardtop', 'hatchback', 'heap', 'horseless_carriage', 'hot-rod', 'hot_rod', 'jalopy', 'jeep', 'landrover', 'limo', 'limousine', 'loaner', 'minicar', 'minivan', 'pace_car', 'patrol_car', 'phaeton', 'police_car', 'police_cruiser', 'prowl_car', 'race_car', 'racer', 'racing_car', 'roadster', 'runabout', 'saloon', 'secondhand_car', 'sedan', 'sport_car', 'sport_utility', 'sport_utility_vehicle', 'sports_car', 'squad_car', 'station_waggon', 'station_wagon', 'stock_car', 'subcompact', 'subcompact_car', 'taxi', 'taxicab', 'tourer', 'touring_car', 'two-seater', 'used-car', 'waggon', 'wagon']\n"
     ]
    }
   ],
   "source": [
    "'''Navigate between concepts with hyponyms'''\n",
    "car = wn.synset('car.n.01')\n",
    "types_of_cars = car.hyponyms()\n",
    "print(sorted(lemma.name() for synset in types_of_cars for lemma in synset.lemmas()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('motor_vehicle.n.01')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''You can also navigate up the hierarchy by visiting hypernyms. \n",
    "Some words have multiple paths, because they can be classified in more than one way. \n",
    "There are two paths between car.n.01 and entity.n.01 because \n",
    "wheeled_vehicle.n.01 can be classified as both a vehicle and a container.'''\n",
    "\n",
    "print(car.hypernyms())\n",
    "paths = car.hypernym_paths()\n",
    "len(paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entity.n.01', 'physical_entity.n.01', 'object.n.01', 'whole.n.02', 'artifact.n.01', 'instrumentality.n.03', 'container.n.01', 'wheeled_vehicle.n.01', 'self-propelled_vehicle.n.01', 'motor_vehicle.n.01', 'car.n.01']\n",
      "---------------------------------------\n",
      "['entity.n.01', 'physical_entity.n.01', 'object.n.01', 'whole.n.02', 'artifact.n.01', 'instrumentality.n.03', 'conveyance.n.03', 'vehicle.n.01', 'wheeled_vehicle.n.01', 'self-propelled_vehicle.n.01', 'motor_vehicle.n.01', 'car.n.01']\n"
     ]
    }
   ],
   "source": [
    "print([synset.name() for synset in paths[0]])\n",
    "print('---------------------------------------')\n",
    "print([synset.name() for synset in paths[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We can get the most general hypernyms (or root hypernyms) of a synset as follows'''\n",
    "car.root_hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('burl.n.02'),\n",
       " Synset('crown.n.07'),\n",
       " Synset('limb.n.02'),\n",
       " Synset('stump.n.01'),\n",
       " Synset('trunk.n.01')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''More Lexical Relations'''\n",
    "wn.synset('tree.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('heartwood.n.01'), Synset('sapwood.n.01')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Meronyms\n",
    "wn.synset('tree.n.01').substance_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('forest.n.01')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Holonyms\n",
    "wn.synset('tree.n.01').member_holonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch.n.02: (often followed by `of') a large number or amount or extent\n",
      "mint.n.02: any north temperate plant of the genus Mentha with aromatic leaves and small mauve flowers\n",
      "mint.n.03: any member of the mint family of plants\n",
      "mint.n.04: the leaves of a mint plant used fresh or candied\n",
      "mint.n.05: a candy that is flavored with a mint oil\n",
      "mint.n.06: a plant where money is coined by authority of the government\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('mint', wn.NOUN):\n",
    "    print(synset.name() + ':', synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('mint.n.02')]\n",
      "[Synset('mint.n.05')]\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('mint.n.04').part_holonyms())\n",
    "print(wn.synset('mint.n.04').substance_holonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('step.v.01')]\n"
     ]
    }
   ],
   "source": [
    "#Entailment\n",
    "print(wn.synset('walk.v.01').entailments())\n",
    "#print(wn.synset('eat.v.01').entailments())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('demand.n.02.demand')]\n",
      "[Lemma('linger.v.04.linger')]\n",
      "[Lemma('inclined.a.02.inclined'), Lemma('vertical.a.01.vertical')]\n",
      "[Lemma('legato.r.01.legato')]\n"
     ]
    }
   ],
   "source": [
    "#Antonyms\n",
    "print(wn.lemma('supply.n.02.supply').antonyms())\n",
    "print(wn.lemma('rush.v.01.rush').antonyms())\n",
    "print(wn.lemma('horizontal.a.01.horizontal').antonyms())\n",
    "print(wn.lemma('staccato.r.01.staccato').antonyms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minke hypernym:\n",
      "[Synset('baleen_whale.n.01')]\n",
      "Orca: hypernym: \n",
      "[Synset('whale.n.02')]\n",
      "Tortoise hypernym: \n",
      "[Synset('vertebrate.n.01')]\n",
      "Novel hypernym: \n",
      "[Synset('entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "'''Semantic Similarity'''\n",
    "right = wn.synset('right_whale.n.01')\n",
    "orca = wn.synset('orca.n.01')\n",
    "minke = wn.synset('minke_whale.n.01')\n",
    "tortoise = wn.synset('tortoise.n.01')\n",
    "novel = wn.synset('novel.n.01')\n",
    "print(\"Minke hypernym:\")\n",
    "print(right.lowest_common_hypernyms(minke))\n",
    "print(\"Orca: hypernym: \")\n",
    "print(right.lowest_common_hypernyms(orca))\n",
    "print(\"Tortoise hypernym: \")\n",
    "print(right.lowest_common_hypernyms(tortoise))\n",
    "print(\"Novel hypernym: \")\n",
    "print(right.lowest_common_hypernyms(novel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#synset depth\n",
    "wn.synset('baleen_whale.n.01').min_depth()\n",
    "\n",
    "#wn.synset('whale.n.02').min_depth()\n",
    "\n",
    "#wn.synset('vertebrate.n.01').min_depth()\n",
    "\n",
    "#wn.synset('entity.n.01').min_depth()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Similarity Scores'''\n",
    "right.path_similarity(minke)\n",
    "\n",
    "# right.path_similarity(orca)\n",
    "\n",
    "# right.path_similarity(tortoise)\n",
    "\n",
    "# right.path_similarity(novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('plant.n.01'), Synset('plant.n.02'), Synset('plant.n.03'), Synset('plant.n.04')]\n"
     ]
    }
   ],
   "source": [
    "'''Example: Using WordNet to find organisms in biology texts'''\n",
    "\n",
    "senses = (wn.synsets('plant', pos=\"n\"))\n",
    "print(senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Def 1: buildings for carrying on industrial labor\n",
      "Def 2: (botany) a living organism lacking the power of locomotion\n",
      "Def 3: an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
      "Def 4: something planted secretly for discovery by another\n"
     ]
    }
   ],
   "source": [
    "s1 = senses[0]\n",
    "s2 = senses[1]\n",
    "s3 = senses[2]\n",
    "s4 = senses[3]\n",
    "d1 = (s1.definition()) \n",
    "print(\"Def 1: \" + str(d1))\n",
    "d2 = (s2.definition())\n",
    "print(\"Def 2: \" + str(d2))\n",
    "d3 = (s3.definition())\n",
    "print(\"Def 3: \" + str(d3))\n",
    "d4 = (s4.definition()) \n",
    "print(\"Def 4: \" + str(d4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load text\n",
    "def readMe(file):\n",
    "    raw_text = open(file, 'r')\n",
    "    raw_text = raw_text.read()\n",
    "    return raw_text\n",
    "\n",
    "text = readMe(\"/Users/hclent/Desktop/NLTK-tutorial/texts/18952863_4.txt\")\n",
    "#print(fcorpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def formatCorpus(corpus): #as string\n",
    "    corpus = corpus.replace(\"_\", \"underscore\") #underscores will make problems for buildDict and are unimportant for my NER\n",
    "    #make untagged corpus\n",
    "    untagged_corpus = corpus.lower()\n",
    "    #untagged_corpus = untagged_corpus.split() #tokenize\n",
    "    untagged_corpus = nltk.word_tokenize(untagged_corpus)\n",
    "    stopwords = nltk.corpus.stopwords.words('english') #delete stopwords from untagged\n",
    "    untagged_corpus = [w for w in untagged_corpus if w.lower() not in stopwords]\n",
    "\n",
    "\n",
    "    return untagged_corpus\n",
    "\n",
    "untagged_corpus = formatCorpus(text)\n",
    "#print(untagged_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use WordNet to find organisms\n",
    "def wordNetNER(document):\n",
    "    plant_sns = (wn.synsets('plant', pos=\"n\"))\n",
    "    plant = plant_sns[1] #(botany) a living organism lacking the power of locomotion #hardcoded\n",
    "\n",
    "    wordnet_names = []\n",
    "    \n",
    "    for word in document:\n",
    "\n",
    "        mySynsets = wn.synsets(word, pos=\"n\") #look at nouns\n",
    "\n",
    "\n",
    "        i = 0\n",
    "        for i in range(0, 3):\n",
    "            try:\n",
    "                given_word = mySynsets[i] #tries first 3 synsets\n",
    "                definition = (given_word.definition())\n",
    "                p1 = re.compile('plant(s?)\\s')\n",
    "                p2 = re.compile('organism(s?)\\s')\n",
    "                p3 = re.compile('animal(s?)\\s')\n",
    "                match1 = p1.search(definition)\n",
    "                match2 = p2.search(definition)\n",
    "                match3 = p3.search(definition)\n",
    "\n",
    "                if match1 or match2 or match3:  #if word has \"plants\" or \"animals\" in the def, check how similar\"\n",
    "                    similarity_score = (given_word.path_similarity(plant)) #check similarity score\n",
    "                    if similarity_score >= 0.2:\n",
    "                        #print(similarity_score)\n",
    "                        #print (\"The words: \"+(str(given_word)) + \"  has a sim score of:  \" +str(similarity_score))\n",
    "                        wordnet_names.append(word)\n",
    "                i += 1\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "    wordnet_ner = (list(unique_everseen(wordnet_names)))\n",
    "    return wordnet_ner\n",
    "\n",
    "wordnet_names = wordNetNER(untagged_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDNET: \n",
      "['lupin', 'legumes', 'bacteria', 'clones', 'simple', 'legume', 'plant', 'bean', 'cell', 'cells', 'crops', 'plants', 'clone', 'peanut', 'recombinant', 'lupins', 'eukaryotes', 'diploid', 'animal']\n"
     ]
    }
   ],
   "source": [
    "print(\"WORDNET: \")\n",
    "print(wordnet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pyNLP]",
   "language": "python",
   "name": "conda-env-pyNLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
