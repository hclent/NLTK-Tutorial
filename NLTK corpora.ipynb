{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Brown Corpus'''\n",
    "from nltk.corpus import brown\n",
    "(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Now', 'that', 'he', 'knew', 'himself', 'to', 'be', ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='science_fiction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Now', 'that', 'he', 'knew', 'himself', 'to', 'be', ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(fileids=['cm01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 the  war  god planet kiss funny \n",
      "           news 5580   20    0    0    0    0 \n",
      "       religion 2295   14    5    1    0    0 \n",
      "        hobbies 4300   12    0    0    0    0 \n",
      "science_fiction  652    2    0   10    0    0 \n",
      "        romance 2758   11    5    0    3    7 \n",
      "          humor  930    1    1    0    0   17 \n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (genre, word)\n",
    "    for genre in brown.categories()\n",
    "    for word in brown.words(categories=genre))\n",
    "\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "#questions = ['who', 'what', 'when', 'where', 'why', 'how']\n",
    "words = ['the', 'war', 'god', 'planet', 'kiss', 'funny']\n",
    "\n",
    "cfd.tabulate(conditions=genres, samples=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', '1801-Jefferson.txt', '1805-Jefferson.txt', '1809-Madison.txt', '1813-Madison.txt', '1817-Monroe.txt', '1821-Monroe.txt', '1825-Adams.txt', '1829-Jackson.txt', '1833-Jackson.txt', '1837-VanBuren.txt', '1841-Harrison.txt', '1845-Polk.txt', '1849-Taylor.txt', '1853-Pierce.txt', '1857-Buchanan.txt', '1861-Lincoln.txt', '1865-Lincoln.txt', '1869-Grant.txt', '1873-Grant.txt', '1877-Hayes.txt', '1881-Garfield.txt', '1885-Cleveland.txt', '1889-Harrison.txt', '1893-Cleveland.txt', '1897-McKinley.txt', '1901-McKinley.txt', '1905-Roosevelt.txt', '1909-Taft.txt', '1913-Wilson.txt', '1917-Wilson.txt', '1921-Harding.txt', '1925-Coolidge.txt', '1929-Hoover.txt', '1933-Roosevelt.txt', '1937-Roosevelt.txt', '1941-Roosevelt.txt', '1945-Roosevelt.txt', '1949-Truman.txt', '1953-Eisenhower.txt', '1957-Eisenhower.txt', '1961-Kennedy.txt', '1965-Johnson.txt', '1969-Nixon.txt', '1973-Nixon.txt', '1977-Carter.txt', '1981-Reagan.txt', '1985-Reagan.txt', '1989-Bush.txt', '1993-Clinton.txt', '1997-Clinton.txt', '2001-Bush.txt', '2005-Bush.txt', '2009-Obama.txt']\n"
     ]
    }
   ],
   "source": [
    "'''Inaugural Address Corpus'''\n",
    "from nltk.corpus import inaugural\n",
    "print(inaugural.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1789', '1793', '1797', '1801', '1805', '1809', '1813', '1817', '1821', '1825', '1829', '1833', '1837', '1841', '1845', '1849', '1853', '1857', '1861', '1865', '1869', '1873', '1877', '1881', '1885', '1889', '1893', '1897', '1901', '1905', '1909', '1913', '1917', '1921', '1925', '1929', '1933', '1937', '1941', '1945', '1949', '1953', '1957', '1961', '1965', '1969', '1973', '1977', '1981', '1985', '1989', '1993', '1997', '2001', '2005', '2009']\n"
     ]
    }
   ],
   "source": [
    "print([fileid[:4] for fileid in inaugural.fileids()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (target, fileid[:4])\n",
    "    for fileid in inaugural.fileids()\n",
    "    for w in inaugural.words(fileid)\n",
    "    for target in ['america','black', 'war', 'vietnam','russia', 'communis']\n",
    "    if w.lower().startswith(target))\n",
    "\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firefox.txt Cookie Manager: \"Don't allow sites that set removed cookies to se ...\n",
      "grail.txt SCENE 1: [wind] [clop clop clop] \n",
      "KING ARTHUR: Whoa there!  [clop ...\n",
      "overheard.txt White guy: So, do you have any plans for this evening?\n",
      "Asian girl ...\n",
      "pirates.txt PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST, by Ted Elliott & Terr ...\n",
      "singles.txt 25 SEXY MALE, seeks attrac older single lady, for discreet encoun ...\n",
      "wine.txt Lovely delicate, fragrant Rhone wine. Polished leather and strawb ...\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import webtext\n",
    "for fileid in webtext.fileids():\n",
    "    print(fileid, webtext.raw(fileid)[:65], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Всеобщая',\n",
       " 'декларация',\n",
       " 'прав',\n",
       " 'человека',\n",
       " 'Принята',\n",
       " 'и',\n",
       " 'провозглашена',\n",
       " 'резолюцией',\n",
       " '217',\n",
       " 'А',\n",
       " '(',\n",
       " 'III',\n",
       " ')',\n",
       " 'Генеральной',\n",
       " 'Ассамблеи']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.corpus.udhr.fileids()\n",
    "nltk.corpus.udhr.words('Russian_Russky-UTF8')[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n      The Reuters-21578 benchmark corpus, ApteMod version\\n\\nThis is a publically available version of the well-known Reuters-21578\\n\"ApteMod\" corpus for text categorization.  It has been used in\\npublications like these:\\n\\n * Yiming Yang and X. Liu. \"A re-examination of text categorization\\n   methods\".  1999.  Proceedings of 22nd Annual International SIGIR.\\n   http://citeseer.nj.nec.com/yang99reexamination.html\\n\\n * Thorsten Joachims. \"Text categorization with support vector\\n   machines: learning with many relevant features\".  1998. Proceedings\\n   of ECML-98, 10th European Conference on Machine Learning.\\n   http://citeseer.nj.nec.com/joachims98text.html\\n\\nApteMod is a collection of 10,788 documents from the Reuters financial\\nnewswire service, partitioned into a training set with 7769 documents\\nand a test set with 3019 documents.  The total size of the corpus is\\nabout 43 MB.  It is also available for download from\\nhttp://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html ,\\nwhich includes a more extensive history of the data revisions.\\n\\nThe distribution of categories in the ApteMod corpus is highly skewed,\\nwith 36.7% of the documents in the most common category, and only\\n0.0185% (2 documents) in each of the five least common categories.\\nIn fact, the original data source is even more skewed---in creating\\nthe corpus, any categories that did not contain at least one document\\nin the training set and one document in the test set were removed from\\nthe corpus by its original creator.\\n\\nIn the ApteMod corpus, each document belongs to one or more\\ncategories.  There are 90 categories in the corpus.  The average\\nnumber of categories per document is 1.235, and the average number of\\ndocuments per category is about 148, or 1.37% of the corpus.\\n\\n -Ken Williams\\n  ken@mathforum.org\\n\\n         Copyright & Notification \\n\\n(extracted from the README at the UCI address above)\\n\\nThe copyright for the text of newswire articles and Reuters\\nannotations in the Reuters-21578 collection resides with Reuters Ltd.\\nReuters Ltd. and Carnegie Group, Inc. have agreed to allow the free\\ndistribution of this data *for research purposes only*.  \\n\\nIf you publish results based on this data set, please acknowledge\\nits use, refer to the data set by the name \"Reuters-21578,\\nDistribution 1.0\", and inform your readers of the current location of\\nthe data set (see \"Availability & Questions\").\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "reuters.readme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pyNLP]",
   "language": "python",
   "name": "conda-env-pyNLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
